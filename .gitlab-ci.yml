stages:
- "test"
- "clean"
- "build"
- "staging"
- "deploy"
- "stop"

services:
- name: docker:dind
  alias: docker
variables:
  DOCKER_HOST: tcp://docker:2375
  DOCKER_TLS_CERTDIR: ""

.initial-setup:
  stage: test
  image: python:3.10.8-slim-buster
  tags:
  - kubernetes-runner
  - docker-runner
  except:
  - tags
  variables:
    PIP_DEFAULT_TIMEOUT: 300
  before_script:
  - pip install poetry==1.1.7
  - poetry config virtualenvs.create false
  - poetry update
  - poetry install

black:
  when: manual
  extends:
  - .initial-setup
  script:
  - black --check .

flake8:
  when: manual
  extends:
  - .initial-setup
  script:
  - flake8 --count .

mypy:
  when: manual
  extends:
  - .initial-setup
  script:
  - mypy .

pytest:
  when: manual
  extends:
  - .initial-setup
  services:
  - name: postgres:13.8-bullseye
    alias: database
  variables:
    # Postgresql variables
    SLACK_FASTAPI_DB_HOST: database
    POSTGRES_PASSWORD: slack_fastapi
    POSTGRES_USER: slack_fastapi
    POSTGRES_DB: slack_fastapi
  script:
  - apt update
  - apt install -y wait-for-it
  - wait-for-it -t 180 $SLACK_FASTAPI_DB_HOST:5432
  - pytest -vv --junitxml=report.xml --cov="slack_fastapi" .
  - coverage xml
  artifacts:
    when: always
    reports:
      junit: report.xml

stage-clean:
  stage: clean
  image: bitnami/kubectl:latest
  script:
    - echo "$KUBE_CONFIG" > kubeconfig
    - export KUBECONFIG=kubeconfig
    - kubectl delete namespace staging --ignore-not-found=true
  tags:
    - kubernetes-runner
  environment:
    name: staging
  when: manual

clean:
  stage: clean
  image: bitnami/kubectl:latest
  script:
    - echo "$KUBE_CONFIG" > kubeconfig
    - export KUBECONFIG=kubeconfig
    - kubectl delete namespace production --ignore-not-found=true
  tags:
    - kubernetes-runner
  environment:
    name: production
  when: manual

# Build stages for different environments
stage-build:
  <<: *build_definition
  environment:
    name: staging
  variables:
    IMAGE_TAG: "staging-${CI_COMMIT_REF_SLUG}"

build:
  <<: *build_definition
  environment:
    name: production
  variables:
    IMAGE_TAG: "production-${CI_COMMIT_REF_SLUG}"

staging:
  stage: staging
  image: bitnami/kubectl:latest
  script:
    - echo "$KUBE_CONFIG" > kubeconfig
    - export KUBECONFIG=kubeconfig
    - kubectl create namespace staging --dry-run=client -o yaml | kubectl apply -f -
    - sed -i "s|__APP_IMAGE__|${CI_REGISTRY_IMAGE}:staging-${CI_COMMIT_REF_SLUG}|g" k8s/app.yml
    - kubectl apply -f k8s/app.yml -n staging
  tags:
    - kubernetes-runner
  environment:
    name: staging
  only:
    - tags

deploy:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - echo "$KUBE_CONFIG" > kubeconfig
    - export KUBECONFIG=kubeconfig
    - kubectl create namespace production --dry-run=client -o yaml | kubectl apply -f -
    - sed -i "s|__APP_IMAGE__|${CI_REGISTRY_IMAGE}:production-${CI_COMMIT_REF_SLUG}|g" k8s/app.yml
    - kubectl apply -f k8s/app.yml -n production
  tags:
    - kubernetes-runner
  environment:
    name: production
  only:
    - main

stage-stop:
  stage: stop
  image: bitnami/kubectl:latest
  script:
    - echo "$KUBE_CONFIG" > kubeconfig
    - export KUBECONFIG=kubeconfig
    # Add commands to stop or scale down your staging deployment
    - kubectl scale deployment slack-fastapi-app --replicas=0 -n staging
  tags:
    - kubernetes-runner
  environment:
    name: staging
  when: manual

stop:
  stage: stop
  image: bitnami/kubectl:latest
  script:
    - echo "$KUBE_CONFIG" > kubeconfig
    - export KUBECONFIG=kubeconfig
    # Add commands to stop or scale down your production deployment
    - kubectl scale deployment slack-fastapi-app --replicas=0 -n production
  tags:
    - kubernetes-runner
  environment:
    name: production
  when: manual
